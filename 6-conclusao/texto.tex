\chapter{Conclusão e Trabalhos Futuros}


Muitos foram as dificuldades encontradas durante o desenvolvimento deste trabalho, desde a coleta 
dos dados, visto que é de difícil encontrar bases de dados anotadas para a tarefa de detecção de sarcasmo
em português. A única base de dados que foi encontrada, era uma base privada, o que dificultou o
desenvolvimento do trabalho, visto que não foi possível compartilhar a base de dados utilizada para
treinamento e avaliação dos modelos. A alternativa encontrada foi a criação de uma base de dados própria,
traduzindo uma base de dados em inglês para o português. Existem sites de notícias que possuiam 
manchetes sarcásticas, porém não seria possível utilizar essas manchetes, visto que elas eram 
protegidas por direitos autorais. A tradução não é algo ideal, visto que o sarcasmo pode ser
culturalmente dependente, e uma frase sarcástica em inglês pode ser que não funcione da mesma
forma em português. Com ajuda de modelos de linguagem, como o GPT-4.1 Mini, foi possível
realizar a tradução de forma satisfatória, porém ainda assim, a base de dados criada não foi a mais 
linguisticamente rica possível. 


No entanto, mesmo com as dificuldades encontradas, foi possível alcançar bons resultados com os modelos
propostos. O modelo BiLSTM apresentou um F1-score de .83, enquanto o modelo BERT-BiLSTM alcançou um F1-score de .85,
indicando que a incorporação do BERT trouxe melhorias no desempenho do modelo como esperado. Esses resultados são 
promissores, considerando as limitações da base de dados utilizada. É interessante notar que, embora o BERT tenha 
melhorado o desempenho, a diferença não foi tão significativa. Isso indica que o modelo BiLSTM já era bastante eficaz 
para a tarefa, isso somente com o texto como entrada, sem utilizar recursos linguísticos adicionais, apenas
embeddings pré-treinados. Lembrado que embeddings nada mais são do que representações vetoriais das palavras, que capturam
seu significado e contexto de uso. Visto que o BERT é um modelo pré-treinado que já possui conhecimento linguístico mais 
amplo e contextual, pensava-se que a diferença seria maior. 


No entanto, os modelos propostos demonstraram ser eficazes para a tarefa de 
detecção de sarcasmo em textos em português, superando modelos tradicionais de machine learning em várias métricas.
Mostrando que para a tarefa de detecção de sarcasmo em headslines em português, podem ser utilizados modelos baseados 
em redes neurais recorrentes.


Para trabalhos futuros, seria interessante explorar outras arquiteturas de modelos, como transformers mais avançados, 
ou mesmo modelos híbridos que combinem diferentes abordagens. Além disso, uma base de dados em 
português mais rica e diversificada poderia ser criada e utilizada para treinar e avaliar os modelos, 
o que poderia levar a melhorias significativas no desempenho e na generalização dos modelos desenvolvidos.
