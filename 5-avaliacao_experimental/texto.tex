\chapter{Avaliação Experimental}
\label{chap:Resultados}

Neste capítulo, serão apresentados os experimentos realizados para avaliar o desempenho do modelo 
proposto na detecção de sarcasmo em títulos de notícias em português. Serão descritos os dados utilizados,
as métricas de avaliação adotadas, os resultados obtidos e uma análise comparativa com outros modelos 
existentes na literatura.


\section{Métricas de Avaliação}
Como descrito no Capítulo 2, para avaliar o desempenho do modelo proposto, foram utilizadas as seguintes métricas:
\begin{itemize}
    \item Acurácia: Mede a proporção de previsões corretas em relação ao total de previsões realizadas.
    \item Precisão: Mede a proporção de verdadeiros positivos em relação ao total de positivos previstos pelo modelo.
    \item Recall: Mede a proporção de verdadeiros positivos em relação ao total de positivos reais no conjunto de dados.
    \item F1-Score: É a média harmônica entre precisão e recall, fornecendo uma medida balanceada do desempenho do modelo.
\end{itemize}
Essas métricas foram escolhidas devido à sua capacidade de fornecer uma visão abrangente do desempenho do modelo, 
considerando tanto a capacidade de identificar corretamente os exemplos positivos quanto a capacidade de evitar falsos 
positivos. A principal métrica utilizada para comparar o desempenho dos modelos foi o F1-Score, pois ele leva em conta 
tanto a precisão quanto o recall, sendo especialmente útil em situações onde há um desequilíbrio entre as classes. 
Um F1-Score mais alto indica tanto uma alta precisão quanto um alto recall, refletindo um desempenho geral melhor do 
modelo na tarefa de detecção de sarcasmo.


\section{Resultados Obtidos}


Nesta seção, serão apresentados os resultados obtidos pelos experimentos realizados com o modelo proposto,
bem como uma comparação com outros modelos existentes na literatura. Os resultados serão apresentados em termos
das métricas de avaliação descritas anteriormente. A Tabela \ref{tab:resultados} apresenta um resumo dos resultados 
obtidos pelos diferentes modelos na tarefa de detecção de sarcasmo. Os trabalhos listados na tabela são diferentes 
artigos da literatura que abordaram a detecção de sarcasmo utilizando diversas abordagens e bases de dados. 
Eles foram incluídos para fornecer um contexto comparativo para os resultados do modelo proposto neste trabalho.
O símbolo \textbullet indica que o valor exato da métrica não foi reportado no trabalho original.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{5-avaliacao_experimental/figuras/acuracia_loss_graphic_bert_bilstm.png}
    \caption{Gráfico de acurácia e perda durante o treinamento do modelo proposto.}
    \label{fig:bert_bilstm_graph}
\end{figure}


Antes de avaliar os resultados e comparar com outros modelos, é importante analisar o 
gráfico \ref{fig:bert_bilstm_graph}, que mostra a evolução da acurácia e da perda (loss) 
durante o treinamento do modelo proposto (BERT + BiLSTM). Novamente, a linha azul representa 
o desempenho no conjunto de treinamento, enquanto a linha laranja representa o desempenho no
conjunto de validação. Observa-se que a acurácia no conjunto de treinamento aumenta rapidamente 
nas primeiras épocas e depois começa a se estabilizar, indicando que o modelo está aprendendo 
os padrões dos dados de treinamento. A acurácia no conjunto de validação também aumenta de 
forma gradual, ao chegar na quarta época, as linhas cruzam-se, indicando que o modelo está começando a 
apresentar sinais de sobreajuste (sobreajuste). A perda (loss) diminui consistentemente no conjunto de
treinamento, o que é esperado à medida que o modelo aprende. No entanto, após a quarta época, a perda no
conjunto de validação começa a aumentar, reforçando a indicação de sobreajuste.

Essa análise sugere que o modelo proposto está aprendendo efetivamente os padrões dos dados, entretanto, 
ela começa a apresentar sinais de sobreajuste após a quarta época. Para mitigar esse problema, o Early
Stopping foi implementado, interrompendo o treinamento quando o desempenho no conjunto de validação, pois
não melhorou por 3 épocas consecutivas. Isso ajuda a garantir que o modelo mantenha um bom desempenho em dados 
não vistos, evitando o sobreajuste excessivo aos dados de treinamento.

A curva ROC (\textit{Receiver Operating Characteristic}) do modelo proposto é apresentada na Figura 
\ref{fig:roc_bert_bilstm}. A curva ROC é uma ferramenta útil para avaliar o desempenho de modelos de
modelagem binária, mostrando a relação entre a taxa de verdadeiros positivos (TPR) e a taxa de falsos positivos (FPR)
em diferentes limiares de decisão. A área sob a curva ROC (AUC - \textit{Area Under the Curve}) é uma métrica 
que quantifica a capacidade do modelo de diferenciar entre as classes positivas e negativas. Um AUC de 1 indica um modelo 
perfeito, enquanto um AUC de 0,5 indica um modelo que não tem capacidade discriminativa, equivalente a uma
classificação aleatória. 

A linha tracejada na Figura \ref{fig:roc_bert_bilstm} representa a linha de base, que corresponde a um modelo
sem capacidade discriminativa (AUC = 0,5). A curva ROC do modelo proposto está significativamente acima da linha de base,
apresentando uma AUC de aproximadamente 0,93, indicando que o modelo tem uma excelente capacidade de distinguir 
entre títulos sarcásticos e não sarcásticos. Isso sugere que o modelo proposto é eficaz na tarefa de detecção de 
sarcasmo em títulos de notícias em português.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{5-avaliacao_experimental/figuras/curva_roc_bert_bilstm.png}
    \caption{Curva ROC do modelo proposto.}
    \label{fig:roc_bert_bilstm}
\end{figure}

A matriz de confusão do modelo proposto é apresentada na Figura \ref{fig:matriz_confusao_bert_bilstm}.
A matriz de confusão é uma ferramenta útil para visualizar o desempenho de um modelo de classificação,
mostrando o número de verdadeiros positivos (TP), verdadeiros negativos (TN), falsos positivos (FP) e 
falsos negativos (FN). No contexto da detecção de sarcasmo em títulos de notícias, os verdadeiros positivos
são os títulos sarcásticos corretamente classificados como sarcásticos, enquanto os verdadeiros negativos
são os títulos não sarcásticos corretamente classificados como não sarcásticos. Os falsos positivos são os títulos
não sarcásticos incorretamente classificados como sarcásticos, e os falsos negativos são os títulos sarcásticos
incorretamente classificados como não sarcásticos.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{5-avaliacao_experimental/figuras/matriz_confusao_bert_bilstm.png}
    \caption{Matriz de Confusão do modelo proposto.}
    \label{fig:matriz_confusao_bert_bilstm}
\end{figure}

Observa-se na matriz de confusão que o modelo proposto classificou corretamente 1656 títulos sarcásticos (TP) e 
2016 títulos não sarcásticos (TN). Houve 232 falsos positivos (FP) e 389 falsos negativos (FN). Esses resultados 
indicam que o modelo tem uma boa capacidade de classificação, embora haja espaço para melhorias, especialmente na 
redução do número de falsos negativos. A matriz também indica que o modelo é mais eficaz na 
identificação de títulos não sarcásticos do que na identificação de títulos sarcásticos.


\begin{table}[!htp]
    \centering
    \scriptsize
    \caption{Resultados dos Experimentos de Detecção de Sarcasmo}
    \label{tab:resultados}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{|c|cccccc|}
            \cline{2-7}
            \multicolumn{1}{c|}{} & Base de Dados & Linguagem & Acurácia & Precisão & Recall & F1-Score \\
            \hline
            \texttt{BiLSTM} & Headlines & Português & 83\% & 80\% & 82\% & 81\% \\
            \hline
            \texttt{BERT + BiLSTM} & Headlines & Português & 85\% & 87\% & 82\% & 85\% \\
            \hline
            \texttt{MHA-BiLSTM \cite{kumar20} } & Headlines & Inglês & \textbullet & 72\% & 83\% & 77\% \\
            \hline
            \texttt{BiLSTM \cite{shrikhande20}} & Headlines & Inglês & 86\% & 84\% & 86\% & 85\% \\
            \hline
            \texttt{BERT+BiLSTM \cite{nayak22}} & Headlines & Inglês & 89\% & 89\% & 89\% & 89\% \\
            \hline
            \texttt{CNN-BILSTM-Attention \cite{misra}} & Headlines & Inglês & 90\% & \textbullet & \textbullet & \textbullet \\
            \hline
            \texttt{RoBERTa-CNN \cite{pawestri24}} & Headlines & Inglês & 89\% & 88\% & 87\% & 87\% \\
            \hline
            \texttt{RoBERTa-BRNN \cite{pawestri24}} & Headlines & Inglês & 65\% & 66\% & 64\% & 65\% \\
            \hline
            \texttt{RoBERTa+BiLSTM+MHA \cite{khan25}} & Headlines & Inglês & 71\% & 69\% & 62\% & 65\% \\
            \hline
        \end{tabular}%
    }
\end{table}

Os resultados apresentados na Tabela \ref{tab:resultados} indicam que o modelo proposto, BERT + BiLSTM,
superou o modelo BiLSTM simples em todas as métricas avaliadas. A incorporação do BERT como extrator de 
características permitiu capturar melhor o contexto e as nuances da linguagem. No entanto, o modelo 
base foi superado por pouco, indicando que apesar das melhorias trazidas pelo BERT, o BiLSTM ainda é um 
modelo competitivo para a tarefa de detecção de sarcasmo.

Com relação ao modelo base (BiLSTM simples), a matriz de confusão é apresentada na Figura 
\ref{fig:matriz_confusao_bilstm} e a curva ROC na Figura \ref{fig:curva_roc_bilstm}. A curva ROC do modelo 
base mostra uma AUC de aproximadamente 0,91, indicando uma boa capacidade de distinção entre as classes,
embora ligeiramente inferior ao modelo proposto. A matriz de confusão revela que o modelo base classificou 
corretamente 1696 títulos sarcásticos (TP) e 1874 títulos não sarcásticos (TN), com 374 falsos 
positivos (FP) e 349 falsos negativos (FN). Esses resultados sugerem que o modelo base é eficaz, 
mas apresenta uma taxa maior de falsos positivos em comparação com o modelo proposto.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{5-avaliacao_experimental/figuras/matriz_confusao_bilstm.png}
        \caption{Matriz de Confusão do modelo base.}
        \label{fig:matriz_confusao_bilstm}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{5-avaliacao_experimental/figuras/curva_roc_bilstm.png}
        \caption{Curva ROC do modelo base.}
        \label{fig:curva_roc_bilstm}
    \end{minipage}
    \caption{Matriz de confusão e curva ROC do modelo base.}
    \label{fig:matriz_confusao_roc_bilstm}
\end{figure}

Em comparação com outros modelos existentes na literatura, o modelo proposto apresentou um desempenho
competitivo, embora alguns modelos, como o MTL-BiLSTM \cite{tan23} e o CNN-LR \cite{razali21}, tenham 
alcançado métricas superiores. É importante notar que nenhum dos modelos comparados foi testado na 
mesma base de dados, os trabalhos acima utilizaram uma aboradagem para detecção de sarcasmo em textos
em inglês, enquanto o presente trabalho focou em títulos de notícias em português. A comparação direta
dos resultados deve ser feita com cautela, considerando as diferenças nas bases de dados e nas
abordagens utilizadas.


Se comparado com os trabalhos que utilizaram a mesma base de dados de notícias sarcásticas em inglês,
o modelo proposto ficou atrás apenas do modelo BERT + BiLSTM \cite{nayak22}, que alcançou um F1-Score de 
89\%. Mesmos modelos utilizando RoBERTa, um modelo mais recente e robusto que o BERT, como o RoBERTa + BiLSTM + MHA 
\cite{khan25} e os modelos propostos por \citet{pawestri24} ficaram atrás do modelo proposto, indicando que a 
incorporação do BERT como extrator de características foi eficaz para a tarefa de detecção de sarcasmo em títulos
de notícias em português.


Os resultados obtidos indicam que o modelo proposto é eficaz na detecção de sarcasmo em títulos de 
notícias em português, mas há espaço para melhorias. Futuras pesquisas podem explorar a incorporação 
de outras técnicas de pré-processamento, arquiteturas de modelos mais complexas e a utilização de
bases de dados maiores e mais diversificadas para aprimorar ainda mais o desempenho na tarefa de
detecção de sarcasmo.


\section{Considerações}


Neste capítulo, foram apresentados os experimentos realizados para avaliar o desempenho do modelo 
proposto na detecção de sarcasmo em títulos de notícias em português. Os resultados indicaram que a 
incorporação do BERT como extrator de características melhorou o desempenho em relação ao modelo BiLSTM 
simples. No entanto, o modelo proposto ainda ficou atrás de alguns modelos existentes na literatura, especialmente aqueles 
utilizando abordagens de aprendizado multitarefa. A comparação dos resultados deve ser feita com cautela, considerando as diferenças nas bases de dados e nas 
abordagens utilizadas. Futuras pesquisas podem explorar novas técnicas e arquiteturas para aprimorar ainda mais o
desempenho na tarefa de detecção de sarcasmo.

